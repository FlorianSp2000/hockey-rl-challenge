name: SAC
params:
  batch_size: 256
  gamma: 0.99
  learning_rate: 0.0003
  learning_starts: 100 # warm up steps
  implementation: sb3  # Options: "custom", "sb3", "other"
  policy: "MlpPolicy" # only for sb3
  eval_interval: 5000
  gradient_steps: 1 # gradient_steps determines the number of parameter updates performed during each training iteration, while train_freq controls the frequency of training updates
  net_arch: {pi: [256, 256], qf: [256, 256]}
  activation_fn: "ReLU"
  tau: 0.005
  buffer_size: 1000000
  train_freq: 1 # takes tuple for (int, str) for (n_updates, "step" or "episode")
  use_sde: False
  sde_sample_freq: -1 # -1 = only sample at rollout beginning 
  log_std_init: -3
  replay_buffer_class: "" # Choose between  ERE, PER or ERE+PER, if "" internally defaults to SB3 ReplayBuffer class
  replay_buffer_kwargs:
    eta: 0.996 
    cmin: 5000