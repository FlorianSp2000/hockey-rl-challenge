mode: train
algorithm: SAC
implementation: sb3  # Options: "custom", "sb3", "other"
env: "Hockey-v1" # "HockeyWrapped-v0"
total_timesteps: 1000000
eval_interval: 5000
batch_size: 256
learning_rate: 0.0003
gamma: 0.99
policy: "MlpPolicy" # only for sb3
learning_starts: 100
log_dir: "logs/SAC/sb3/train"
tensorboard_log: logs/SAC/sb3/train
policy_kwargs: {}
seed: 42
parallelize: False
n_eval_envs: 2
gradient_steps: 1